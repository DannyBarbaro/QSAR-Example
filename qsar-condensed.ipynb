{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Simple QSAR example from a 2017 drug design workshop\n",
    "Danny Barbaro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem, Descriptors\n",
    "# from rdkit.Chem.Draw import IPythonConsole\n",
    "# from rdkit.Chem import Draw\n",
    "# IPythonConsole.ipython_useSVG=True\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, matthews_corrcoef\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logBB is a database of molecules\n",
    "file_name = \"data/logBB.sdf\"\n",
    "molecules = []\n",
    "y = []\n",
    "# Get all the molecules out of the database and parse them with the Chem library\n",
    "for molecule in Chem.SDMolSupplier(file_name):\n",
    "    if molecule is not None:\n",
    "        molecules.append(molecule)\n",
    "        y.append(molecule.GetIntProp(\"logBB_class\"))\n",
    "fingerprints = [AllChem.GetMorganFingerprintAsBitVect(m, 2) for m in molecules]\n",
    "\n",
    "def rdkit_numpy_convert(fingerprints):\n",
    "    output = []\n",
    "    for fingerprint in fingerprints:\n",
    "        arr = np.zeros((1,))\n",
    "        DataStructs.ConvertToNumpyArray(fingerprint, arr)\n",
    "        output.append(arr)\n",
    "    return np.asarray(output)\n",
    "\n",
    "x = rdkit_numpy_convert(fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(321, 2048)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape\n",
    "print(\"Balance:\", str(sum(y) / len(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the whole set on training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_training, x_testing, y_training, y_testing = train_test_split(x, y, test_size=0.20, random_state=seed)\n",
    "cross_validations = StratifiedKFold(n_splits=5, random_state=seed)\n",
    "for i, (train_index, test_index) in enumerate(cross_validations.split(x_training, y_training)):\n",
    "    print(\"\\nFold_\" + str(i))\n",
    "    print(\"TRAIN:\", train_index)\n",
    "    print(\"TEST:\", test_index)\n",
    "scaler = StandardScaler().fit(x_training)\n",
    "x_training = scaler.transform(x_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create grid search dictionary\n",
    "parameter_grid = {\"max_features\": [x_training.shape[1] // 10, x_training.shape[1] // 7, x_training.shape[1] // 5, x_training.shape[1] // 3], \n",
    "              \"n_estimators\": [100, 200, 300, 400, 500]}\n",
    "model = GridSearchCV(RandomForestClassifier(), parameter_grid, n_jobs=2, cv=cross_validations, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   26.2s\n[Parallel(n_jobs=2)]: Done  60 out of  60 | elapsed:   37.9s finished\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n  DeprecationWarning)\n"
    },
    {
     "data": {
      "text/plain": "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=73, shuffle=False),\n             error_score='raise-deprecating',\n             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n                                              criterion='gini', max_depth=None,\n                                              max_features='auto',\n                                              max_leaf_nodes=None,\n                                              min_impurity_decrease=0.0,\n                                              min_impurity_split=None,\n                                              min_samples_leaf=1,\n                                              min_samples_split=2,\n                                              min_weight_fraction_leaf=0.0,\n                                              n_estimators='warn', n_jobs=None,\n                                              oob_score=False,\n                                              random_state=None, verbose=0,\n                                              warm_start=False),\n             iid='warn', n_jobs=2,\n             param_grid={'max_features': [204, 292, 409, 682],\n                         'n_estimators': [100, 250, 500]},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring=None, verbose=1)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run model\n",
    "model.fit(x_training, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'max_features': 682, 'n_estimators': 100}"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.80078125"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'mean_fit_time': array([0.43746314, 0.85785494, 1.53192692, 0.34266086, 0.83844147,\n        1.67527976, 0.38311658, 0.95426869, 1.87873321, 0.4984786 ,\n        1.15881963, 2.8201026 ]),\n 'std_fit_time': array([0.18937149, 0.20664881, 0.03771478, 0.00383038, 0.0073081 ,\n        0.00969643, 0.00795306, 0.01067708, 0.01977272, 0.04383401,\n        0.0137222 , 0.4192366 ]),\n 'mean_score_time': array([0.01271443, 0.02134485, 0.04073129, 0.01018934, 0.02102442,\n        0.04052019, 0.00827141, 0.02067394, 0.05436492, 0.009868  ,\n        0.01995416, 0.04068213]),\n 'std_score_time': array([0.00455198, 0.00062809, 0.00216496, 0.00075373, 0.00163178,\n        0.00157054, 0.00114138, 0.00080743, 0.02938982, 0.00164787,\n        0.00097284, 0.00392852]),\n 'param_max_features': masked_array(data=[204, 204, 204, 292, 292, 292, 409, 409, 409, 682, 682,\n                    682],\n              mask=[False, False, False, False, False, False, False, False,\n                    False, False, False, False],\n        fill_value='?',\n             dtype=object),\n 'param_n_estimators': masked_array(data=[100, 250, 500, 100, 250, 500, 100, 250, 500, 100, 250,\n                    500],\n              mask=[False, False, False, False, False, False, False, False,\n                    False, False, False, False],\n        fill_value='?',\n             dtype=object),\n 'params': [{'max_features': 204, 'n_estimators': 100},\n  {'max_features': 204, 'n_estimators': 250},\n  {'max_features': 204, 'n_estimators': 500},\n  {'max_features': 292, 'n_estimators': 100},\n  {'max_features': 292, 'n_estimators': 250},\n  {'max_features': 292, 'n_estimators': 500},\n  {'max_features': 409, 'n_estimators': 100},\n  {'max_features': 409, 'n_estimators': 250},\n  {'max_features': 409, 'n_estimators': 500},\n  {'max_features': 682, 'n_estimators': 100},\n  {'max_features': 682, 'n_estimators': 250},\n  {'max_features': 682, 'n_estimators': 500}],\n 'split0_test_score': array([0.80769231, 0.80769231, 0.78846154, 0.78846154, 0.82692308,\n        0.78846154, 0.78846154, 0.78846154, 0.80769231, 0.82692308,\n        0.76923077, 0.80769231]),\n 'split1_test_score': array([0.76923077, 0.75      , 0.76923077, 0.73076923, 0.75      ,\n        0.76923077, 0.76923077, 0.75      , 0.76923077, 0.75      ,\n        0.80769231, 0.75      ]),\n 'split2_test_score': array([0.78431373, 0.80392157, 0.78431373, 0.78431373, 0.80392157,\n        0.80392157, 0.84313725, 0.78431373, 0.80392157, 0.80392157,\n        0.78431373, 0.82352941]),\n 'split3_test_score': array([0.70588235, 0.7254902 , 0.7254902 , 0.80392157, 0.76470588,\n        0.7254902 , 0.74509804, 0.7254902 , 0.74509804, 0.82352941,\n        0.78431373, 0.78431373]),\n 'split4_test_score': array([0.8 , 0.86, 0.82, 0.88, 0.82, 0.82, 0.84, 0.82, 0.82, 0.8 , 0.78,\n        0.78]),\n 'mean_test_score': array([0.7734375 , 0.7890625 , 0.77734375, 0.796875  , 0.79296875,\n        0.78125   , 0.796875  , 0.7734375 , 0.7890625 , 0.80078125,\n        0.78515625, 0.7890625 ]),\n 'std_test_score': array([0.03622825, 0.04703612, 0.03064629, 0.04788443, 0.03057712,\n        0.03248049, 0.03864306, 0.03259507, 0.02768351, 0.02770912,\n        0.01265521, 0.02525157]),\n 'rank_test_score': array([11,  5, 10,  2,  4,  9,  2, 11,  5,  1,  8,  5], dtype=int32)}"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.7734375 , 0.7890625 , 0.77734375, 0.796875  , 0.79296875,\n       0.78125   , 0.796875  , 0.7734375 , 0.7890625 , 0.80078125,\n       0.78515625, 0.7890625 ])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[{'max_features': 204, 'n_estimators': 100},\n {'max_features': 204, 'n_estimators': 250},\n {'max_features': 204, 'n_estimators': 500},\n {'max_features': 292, 'n_estimators': 100},\n {'max_features': 292, 'n_estimators': 250},\n {'max_features': 292, 'n_estimators': 500},\n {'max_features': 409, 'n_estimators': 100},\n {'max_features': 409, 'n_estimators': 250},\n {'max_features': 409, 'n_estimators': 500},\n {'max_features': 682, 'n_estimators': 100},\n {'max_features': 682, 'n_estimators': 250},\n {'max_features': 682, 'n_estimators': 500}]"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cv_results_['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the scaler to the test set\n",
    "x_testing = scaler.transform(x_testing)\n",
    "prediction_random_forest = model.predict(x_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n       1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Accuracy =  0.7230769230769231\nMCC =  0.45743323311233\nKappa =  0.44967074317968014\n"
    }
   ],
   "source": [
    "print(\"Accuracy = \", accuracy_score(y_testing, prediction_random_forest))\n",
    "print(\"MCC = \", matthews_corrcoef(y_testing, prediction_random_forest))\n",
    "print(\"Kappa = \", cohen_kappa_score(y_testing, prediction_random_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applicability Domain Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_probability = model.predict_proba(x_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.03, 0.97],\n       [0.14, 0.86],\n       [0.61, 0.39],\n       [0.4 , 0.6 ],\n       [0.54, 0.46],\n       [0.05, 0.95],\n       [0.01, 0.99],\n       [0.29, 0.71],\n       [0.57, 0.43],\n       [0.12, 0.88],\n       [0.35, 0.65],\n       [0.27, 0.73],\n       [0.08, 0.92],\n       [0.27, 0.73],\n       [0.31, 0.69],\n       [0.96, 0.04],\n       [0.37, 0.63],\n       [0.56, 0.44],\n       [0.33, 0.67],\n       [0.93, 0.07],\n       [0.  , 1.  ],\n       [0.28, 0.72],\n       [0.48, 0.52],\n       [0.46, 0.54],\n       [0.34, 0.66],\n       [0.41, 0.59],\n       [0.01, 0.99],\n       [0.  , 1.  ],\n       [0.96, 0.04],\n       [0.79, 0.21],\n       [0.84, 0.16],\n       [0.3 , 0.7 ],\n       [0.64, 0.36],\n       [0.65, 0.35],\n       [0.62, 0.38],\n       [0.19, 0.81],\n       [0.57, 0.43],\n       [0.64, 0.36],\n       [0.16, 0.84],\n       [0.65, 0.35],\n       [0.62, 0.38],\n       [0.98, 0.02],\n       [0.12, 0.88],\n       [0.28, 0.72],\n       [0.  , 1.  ],\n       [0.95, 0.05],\n       [0.94, 0.06],\n       [0.37, 0.63],\n       [0.73, 0.27],\n       [0.46, 0.54],\n       [0.49, 0.51],\n       [0.55, 0.45],\n       [0.23, 0.77],\n       [0.92, 0.08],\n       [0.97, 0.03],\n       [0.65, 0.35],\n       [0.03, 0.97],\n       [0.65, 0.35],\n       [0.01, 0.99],\n       [0.86, 0.14],\n       [0.69, 0.31],\n       [0.36, 0.64],\n       [0.83, 0.17],\n       [0.04, 0.96],\n       [0.36, 0.64]])"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the maximum predicted probability for each compound and compare it to the desired threshold\n",
    "da = np.amax(prediction_probability, axis=1) > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([ True,  True, False, False, False,  True,  True, False, False,\n        True, False, False,  True, False, False,  True, False, False,\n       False,  True,  True, False, False, False, False, False,  True,\n        True,  True, False,  True, False, False, False, False,  True,\n       False, False,  True, False, False,  True,  True, False,  True,\n        True,  True, False, False, False, False, False, False,  True,\n        True, False,  True, False,  True,  True, False, False,  True,\n        True, False])"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Time to calculate some statistics for the prediciton probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Accuracy =  0.813953488372093\nMCC =  0.6600586246040802\nKappa =  0.6348195329087049\nCoverage =  0.6615384615384615\n"
    }
   ],
   "source": [
    "print(\"Accuracy = \", accuracy_score(np.asarray(y_testing)[da], prediction_random_forest[da]))\n",
    "print(\"MCC = \", matthews_corrcoef(np.asarray(y_testing)[da], prediction_random_forest[da]))\n",
    "print(\"Kappa = \", cohen_kappa_score(np.asarray(y_testing)[da], prediction_random_forest[da]))\n",
    "print(\"Coverage = \", sum(da) / len(da))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Model: Support-Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = [{'kernel': ['rbf'], 'gamma': [10 ** i for i in range(-6, 0)],\n",
    "                     'C': [10 ** i for i in range(0, 5)]},\n",
    "                    {'kernel': ['linear'], 'C': [10 ** i for i in range(0, 5)]}]\n",
    "svm = GridSearchCV(SVC(probability=True), parameter_grid, n_jobs=2, cv=cross_validations, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   14.9s\n[Parallel(n_jobs=2)]: Done 175 out of 175 | elapsed:   56.6s finished\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n  DeprecationWarning)\n"
    },
    {
     "data": {
      "text/plain": "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=73, shuffle=False),\n             error_score='raise-deprecating',\n             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n                           decision_function_shape='ovr', degree=3,\n                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n                           probability=True, random_state=None, shrinking=True,\n                           tol=0.001, verbose=False),\n             iid='warn', n_jobs=2,\n             param_grid=[{'C': [1, 10, 100, 1000, 10000],\n                          'gamma': [1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1],\n                          'kernel': ['rbf']},\n                         {'C': [1, 10, 100, 1000, 10000],\n                          'kernel': ['linear']}],\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring=None, verbose=1)"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run model\n",
    "svm.fit(x_training, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.7734375"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_svm = svm.predict(x_testing)\n",
    "print(\"Accuracy = \", accuracy_score(y_testing, prediction_svm))\n",
    "print(\"MCC = \", matthews_corrcoef(y_testing, prediction_svm))\n",
    "print(\"Kappa = \", cohen_kappa_score(y_testing, prediction_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediciton_probability = svm.predict_proba(x_testing)\n",
    "da = np.amax(prediciton_probability, axis=1) > threshold\n",
    "print(\"Accuracy = \", accuracy_score(np.asarray(y_testing)[da], prediction_svm[da]))\n",
    "print(\"MCC = \", matthews_corrcoef(np.asarray(y_testing)[da], prediction_svm[da]))\n",
    "print(\"Kappa = \", cohen_kappa_score(np.asarray(y_testing)[da], prediction_svm[da]))\n",
    "print(\"Coverage = \", sum(da) / len(da))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third model: Gradient Boosting Classifier (GBM)\n",
    "#### This will compute the consensus predictions from random forest and SVM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup model\n",
    "parameter_grid = {\"n_estimators\": [100, 200, 300, 400, 500]}\n",
    "gbm = GridSearchCV(GradientBoostingClassifier(subsample=0.5, max_features=0.5), \n",
    "                   parameter_grid, n_jobs=2, cv=cross_validations, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n[Parallel(n_jobs=2)]: Done  25 out of  25 | elapsed:   18.1s finished\n/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n  DeprecationWarning)\n"
    },
    {
     "data": {
      "text/plain": "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=73, shuffle=False),\n             error_score='raise-deprecating',\n             estimator=GradientBoostingClassifier(criterion='friedman_mse',\n                                                  init=None, learning_rate=0.1,\n                                                  loss='deviance', max_depth=3,\n                                                  max_features=0.5,\n                                                  max_leaf_nodes=None,\n                                                  min_impurity_decrease=0.0,\n                                                  min_impurity_split=None,\n                                                  min_samples_leaf=1,\n                                                  min_samples_split=2,\n                                                  min_weight_fraction_leaf=0.0,\n                                                  n_estimators=100,\n                                                  n_iter_no_change=None,\n                                                  presort='auto',\n                                                  random_state=None,\n                                                  subsample=0.5, tol=0.0001,\n                                                  validation_fraction=0.1,\n                                                  verbose=0, warm_start=False),\n             iid='warn', n_jobs=2,\n             param_grid={'n_estimators': [100, 200, 300, 400, 500]},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring=None, verbose=1)"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run model\n",
    "gbm.fit(x_training, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.796875"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'n_estimators': 100}"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_gbm = gbm.predict(x_testing)\n",
    "print(\"Accuracy = \", accuracy_score(y_testing, prediction_gbm))\n",
    "print(\"MCC = \", matthews_corrcoef(y_testing, prediction_gbm))\n",
    "print(\"Kappa = \", cohen_kappa_score(y_testing, prediction_gbm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### consensus model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_consensus = 1 * (((prediction_random_forest + prediction_svm + prediction_gbm) / 3) >= 0.5)\n",
    "print(\"Accuracy = \", accuracy_score(y_testing, prediction_consensus))\n",
    "print(\"MCC = \", matthews_corrcoef(y_testing, prediction_consensus))\n",
    "print(\"Kappa = \", cohen_kappa_score(y_testing, prediction_consensus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Add to the fingerprints some other descriptors and look at the consensus model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate some descriptors\n",
    "descriptors = []\n",
    "for molecule in molecules:\n",
    "    descriptors.append([Descriptors.MolLogP(molecule),\n",
    "                  Descriptors.TPSA(molecule),\n",
    "                  Descriptors.NHOHCount(molecule),\n",
    "                  Descriptors.NOCount(molecule),\n",
    "                  Descriptors.NumHAcceptors(molecule),\n",
    "                  Descriptors.NumHDonors(molecule),\n",
    "                  Descriptors.NumRotatableBonds(molecule),\n",
    "                  Descriptors.NumHeteroatoms(molecule),\n",
    "                  Descriptors.FractionCSP3(molecule)])\n",
    "descriptors = np.asarray(descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate((x, descriptors), axis=1)\n",
    "x_training, x_testing, y_training, y_testing = train_test_split(x, y, test_size=0.20, random_state=seed)\n",
    "scaler = StandardScaler().fit(x_training)\n",
    "x_training = scaler.transform(x_training)\n",
    "parameter_grid = {\"max_features\": [x_training.shape[1] // 10, x_training.shape[1] // 7, x_training.shape[1] // 5, x_training.shape[1] // 3], \n",
    "              \"n_estimators\": [100, 200, 300, 400, 500]}\n",
    "model = GridSearchCV(RandomForestClassifier(), parameter_grid, n_jobs=2, cv=cross_validations, verbose=1)\n",
    "model.fit(x_training, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.86328125"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_testing = scaler.transform(x_testing)\n",
    "prediction = model.predict(x_testing)\n",
    "print(\"Accuracy = \", accuracy_score(y_testing, prediction))\n",
    "print(\"MCC = \", matthews_corrcoef(y_testing, prediction))\n",
    "print(\"Kappa = \", cohen_kappa_score(y_testing, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate applicability domain and calc stat\n",
    "prediction_probability = model.predict_proba(x_testing)\n",
    "da = np.amax(prediction_probability, axis=1) > threshold\n",
    "print(\"Accuracy = \", accuracy_score(np.asarray(y_testing)[da], prediction[da]))\n",
    "print(\"MCC = \", matthews_corrcoef(np.asarray(y_testing)[da], prediction[da]))\n",
    "print(\"Kappa = \", cohen_kappa_score(np.asarray(y_testing)[da], prediction[da]))\n",
    "print(\"Coverage = \", sum(da) / len(da))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Let's try to analyse which variables are the most important in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n                       max_depth=None, max_features=295, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=100,\n                       n_jobs=None, oob_score=False, random_state=73, verbose=0,\n                       warm_start=False)"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rebuild the Random Forest model manually using best parameters to be able to extract additional information from the model\n",
    "random_forest = RandomForestClassifier(n_estimators=model.best_params_[\"n_estimators\"], \n",
    "                           max_features=model.best_params_[\"max_features\"],\n",
    "                           random_state=seed)\n",
    "random_forest.fit(x_training, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = random_forest.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.        , 0.00149662, 0.00025045, ..., 0.00751906, 0.01958647,\n       0.02424284])"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Feature ranking:\n1.\tfeature_index = 2049\t(0.094693)\n2.\tfeature_index = 2058\t(0.082216)\n3.\tfeature_index = 2060\t(0.043471)\n4.\tfeature_index = 2057\t(0.042505)\n5.\tfeature_index = 2051\t(0.037312)\n6.\tfeature_index = 2048\t(0.031235)\n7.\tfeature_index = 2065\t(0.024243)\n8.\tfeature_index = 2055\t(0.023781)\n9.\tfeature_index = 2056\t(0.022325)\n10.\tfeature_index = 2052\t(0.020145)\n11.\tfeature_index = 2061\t(0.020015)\n12.\tfeature_index = 2064\t(0.019586)\n13.\tfeature_index = 650\t(0.018186)\n14.\tfeature_index = 2050\t(0.012931)\n15.\tfeature_index = 2059\t(0.010798)\n16.\tfeature_index = 2053\t(0.008813)\n17.\tfeature_index = 2062\t(0.008812)\n18.\tfeature_index = 2054\t(0.008456)\n19.\tfeature_index = 2063\t(0.007519)\n20.\tfeature_index = 794\t(0.007504)\n21.\tfeature_index = 378\t(0.006732)\n22.\tfeature_index = 892\t(0.005309)\n23.\tfeature_index = 327\t(0.005174)\n24.\tfeature_index = 795\t(0.005014)\n25.\tfeature_index = 807\t(0.004759)\n"
    }
   ],
   "source": [
    "indices = np.argsort(importance)[::-1]\n",
    "\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "# print top 25 features\n",
    "for i in range(25):\n",
    "    print(\"%d.\\tfeature_index = %d\\t(%f)\" % (i + 1, indices[i], importance[indices[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Features with numbers 1-2048 are different auto-generated fingerprints\n",
    "### In the order we defined them, the following feature have the associated indicies\n",
    "\n",
    "2049 - MolLogP --------------- Rank: 1  \n",
    "2050 - TPSA(m) --------------- Rank: 4  \n",
    "2051 - NHOHCount ------------- Rank: 5  \n",
    "2052 - NOCount --------------- Rank: 10  \n",
    "2053 - NumHAcceptors --------- Rank: 16  \n",
    "2054 - NumHDonors ------------ Rank: 18  \n",
    "2055 - NumRotatableBonds ----- Rank: 8  \n",
    "2056 - NumHeteroatoms -------- Rank: 9  \n",
    "2057 - FractionCSP3 ---------- Rank: 4  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}